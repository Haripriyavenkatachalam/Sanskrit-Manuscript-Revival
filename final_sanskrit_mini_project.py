# -*- coding: utf-8 -*-
"""Final_Sanskrit_Mini_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17PK8sz5eqRIXkcEqyuuLZgvYTsrdL9Nl
"""

!pip install pytesseract
!sudo apt install tesseract-ocr

!sudo apt-get install tesseract-ocr-san

!pip install Pillow

!pip install gradio

import cv2
import pytesseract
import re
import string
import gradio as gr
from PIL import Image
import os
from google.colab.patches import cv2_imshow

# Set the path to the Tesseract executable
pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'

# Function to preprocess the image and save the preprocessed image
def preprocess_and_save_image(image_path):
    # Read the image
    image = cv2.imread(image_path)

    # Convert the image to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply adaptive thresholding to binarize the image
    thresholded_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 31, 11)

    # Invert the colors
    inverted_image = cv2.bitwise_not(thresholded_image)

    return inverted_image

# Function to extract text from preprocessed image
def extract_text_from_image(img):
    text = pytesseract.image_to_string(img, lang='san', config='--psm 6')  # Specify Sanskrit language code and PSM 6

    return text

# Path to the original image file
original_image_path = 'hari.png'

# Check if the original image file exists
if os.path.exists(original_image_path):
    # Display the original image
    original_image = cv2.imread(original_image_path)
    cv2_imshow(original_image)  # Display the original image in Colab

    # Preprocess the image and save the preprocessed image
    preprocessed_image = preprocess_and_save_image(original_image_path)
    cv2_imshow(preprocessed_image)  # Display the preprocessed image in Colab

    # Extract text from the preprocessed image
    extracted_text = extract_text_from_image(preprocessed_image)

    # Print the extracted text
    print("\nExtracted Text:")
    print(extracted_text)
else:
    print("Original image file not found.")

#Text preprocessing functions
def clean_and_tokenize_text(text):
    #Remove unwanted characters, punctuation, and whitespace.
    text = re.sub(f"[{string.punctuation}]", "", text)
    text = " ".join(text.split())
    return text

cleaned_and_tokenized_text = clean_and_tokenize_text(extracted_text)
print("Extracted text after cleaning:")
print(cleaned_and_tokenized_text)

!pip install torch
!pip install transformers

from transformers import pipeline

fill_mask = pipeline(
    "fill-mask",
    model="Samuela39/my-awesome-model",
    tokenizer="Samuela39/my-awesome-model"
)

'''
रामो सीतया सह वनम् अयोध्यायाः पित्रे गच्छति।
rāmo sītayā saha vanam ayodhyāyāḥ pitre gacchati.
Rama goes with Sita to the forest from Ayodhya for his father.
'''

fill_mask("रामो सीतया सह वनम् अयोध्यायाः <mask> गच्छति।")

'''def gradio_function(image, text):
  image= preprocess_and_save_image(image)
  extracted_text = extract_text_from_image(image)
  text = clean_and_tokenize_text(extracted_text)

  return f"Extracted text after cleaning:\n {text}"

gr.Interface(
    fn=gradio_function,
    inputs="image",
    outputs="textbox",
    title="Sanskrit Text Restoration",
    description="Upload a Sanskrit manuscript image or Sanskrit text image."
).launch(share=True)'''